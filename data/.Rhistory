#genero modelo glm de Regresión Logística (para probabilidades)
logit1=glm(z ~ x1 + x2 + y, family = gaussian, data=train)
logit2=glm(z ~ x1 + x2 + y, family = binomial(link = "logit"), data=train)
test$pred=predict(object = logi1t1,newdata = test)#crea columna en test con probabilidades de ser 1
test$pred=predict(object = logit1,newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
confusionMatrix(as.factor(test$predbin), as.factor(test$z)) #muestra errores de predicción en el test
test$pred=predict(object = logit2,type = "response",newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
library(caret)
confusionMatrix(as.factor(test$predbin), as.factor(test$z)) #muestra errores de predicción en el test
test$pred=predict(object = logit1,newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
test$predbin
test$pred=predict(object = logit2,type = "response",newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
test$predbin
#genero modelo glm de Regresión Logística (para probabilidades)
logit=glm(z ~ x1 + x2 + y, family = binomial(link = "logit"), data=train)
summary(logit)
test$pred=predict(object = logit,type = "response",newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
library(caret)
confusionMatrix(as.factor(test$predbin), as.factor(test$z)) #muestra errores de predicción en el test
which(is.na(dfc$z))
dfc[is.na(dfc)]=predict(object = logit,newdata = dfpred)#inputa en dff las probabilidades de ser 1 o 0 en la variable z
#asigno 1 o 0 dependiendo la probabilidad
dfc$z[dfc$z>0.5] = 1
dfc$z[dfc$z<=0.5] = 0
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_15" = c(df$z[15],dfnc[15,"z"],dfc[15,"z"],abs(df$z[15]-dfnc[15,"z"]),abs(df$z[15]-dfc[15,"z"])),
"id_25" = c(df$z[25],dfnc[25,"z"],dfc[25,"z"],abs(df$z[25]-dfnc[25,"z"]),abs(df$z[25]-dfc[25,"z"])),
"id_75" = c(df$z[75],dfnc[75,"z"],dfc[75,"z"],abs(df$z[75]-dfnc[75,"z"]),abs(df$z[75]-dfc[75,"z"])))
comparativa
#Genera df
x1=seq(100)+rnorm(100,mean = 0,sd=10)
x2=200+seq(100)+rnorm(100,mean = 2,sd=10)
p=(exp(5+0.8*x1-0.15*x2)/(1+exp(5+0.8*x1-0.15*x2)))+runif(n = 100,min = -0.5,max = 0.5) #construye razón de probabilidad
z=seq(length(p))
for (i in seq(length(p))) { #construye variable categórica
if (p[i]>0.5){
z[i]=1
}else{
z[i]=0
}
}
y<-200+0.75*x1-1.5*x2+0.15*z +rnorm(100,mean = 0,sd=5) #la variable categórica z repercute en el valor de la Y (variable objetivo)
df= cbind(x1,x2,z,y)
df=as.data.frame(df)
df_incompleto=df
df_incompleto$z[15]=NA
df_incompleto$z[25]=NA
df_incompleto$z[75]=NA
dfnc=df_incompleto
frec=sum(dfnc$z,na.rm = TRUE)/length(df$z) #calculo frecuencia de los 1, como es > que 0.5, entonces les pongo a todos los NA un 1
input=0
if (frec>0.5){
input=1
} else{
input=0
}
dfnc$pred=input
dfnc[is.na(dfnc)]=input
dfc=df_incompleto
dfpred= dfc[is.na(dfc$z),] #valores NA a predecir
dftoprove= dfc[!is.na(dfc$z),] #valores con dato
#genera conjuntos train y test
dftoprove$id <- 1:nrow(dftoprove) #creo columna id para joinear
train <- dftoprove %>% dplyr::sample_frac(0.70) #70% como conjunto entrenamiento
test  <- dplyr::anti_join(dftoprove, train, by = 'id') #30% como conjunto prueba
#saco columna id
train=train[,(names(train)!="id")]
test=test[,(names(test)!="id")]
#genero modelo glm de Regresión Logística (para probabilidades)
logit=glm(z ~ x1 + x2 + y, family = binomial(link = "logit"), data=train)
summary(logit)
test$pred=predict(object = logit,type = "response",newdata = test)#crea columna en test con probabilidades de ser 1
test$predbin = (test$pred > 0.5) * 1 #crea columna en test con asignación de 1 o 0 según modelo
library(caret)
confusionMatrix(as.factor(test$predbin), as.factor(test$z)) #muestra errores de predicción en el test
which(is.na(dfc$z))
dfc[is.na(dfc)]=predict(object = logit,newdata = dfpred)#inputa en dff las probabilidades de ser 1 o 0 en la variable z
#asigno 1 o 0 dependiendo la probabilidad
dfc$z[dfc$z>0.5] = 1
dfc$z[dfc$z<=0.5] = 0
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_15" = c(df$z[15],dfnc[15,"z"],dfc[15,"z"],abs(df$z[15]-dfnc[15,"z"]),abs(df$z[15]-dfc[15,"z"])),
"id_25" = c(df$z[25],dfnc[25,"z"],dfc[25,"z"],abs(df$z[25]-dfnc[25,"z"]),abs(df$z[25]-dfc[25,"z"])),
"id_75" = c(df$z[75],dfnc[75,"z"],dfc[75,"z"],abs(df$z[75]-dfnc[75,"z"]),abs(df$z[75]-dfc[75,"z"])))
comparativa
df_incompleto=df
df_incompleto$y[5]=NA
df_incompleto$y[50]=NA
df_incompleto$y[100]=NA
dfnc=df_incompleto
media=mean(dfnc$y,na.rm=TRUE)
dfnc$pred=media
dfnc[is.na(dfnc)]=media
dfnc$pred
dfc=df_incompleto
dfpred= dfc[is.na(dfc$y),]
dftoprove= dfc[!is.na(dfc$y),]
dftoprove$id <- 1:nrow(dftoprove) #creo columna id
train <- dftoprove %>% dplyr::sample_frac(0.70) #70% como conjunto entrenamiento
test  <- dplyr::anti_join(dftoprove, train, by = 'id') #30% como conjunto prueba
train=train[,(names(train)!="id")]
test=test[,(names(test)!="id")]
#crea modelo lm de Regresión Lineal (para valores continuos)
lmlogit=lm(y ~ x1 + x2 + z, data = train)
#es lo mismo que: logit=glm(z ~ x1 + x2 + y, family = gaussian, data=train)
summary(lmlogit) #muestra el R cuadrado del train
test$pred=predict(object = lmlogit,newdata = test) #crea variable en test con las predicciones del dato
test$pred
res=sum((test$y-test$pred)**2)
stc=sum((test$y-mean(test$y))**2)
r_cuadrado=1-res/stc #genera R cuadrado del test
r_cuadrado
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_5" = c(df$y[5],dfnc[5,"y"],dfc[5,"y"],abs(df$y[5]-dfnc[5,"y"]),abs(df$y[5]-dfc[5,"y"])),
"id_50" = c(df$y[50],dfnc[5,"y"],dfc[50,"y"],abs(df$y[50]-dfnc[50,"y"]),abs(df$y[50]-dfc[50,"y"])),
"id_100" = c(df$y[100],dfnc[5,"y"],dfc[100,"y"],abs(df$y[100]-dfnc[100,"y"]),abs(df$y[100]-dfc[100,"y"])))
comparativa
res=sum((dfnc$y-dfnc$pred)**2)
stc=sum((dfnc$y-mean(dfnc$y))**2)
r_cuadrado=1-res/stc #genera R cuadrado del test
r_cuadrado
dfnc$y
dfnc$pred
res
stc
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_5" = c(df$y[5],dfnc[5,"y"],dfc[5,"y"],abs(df$y[5]-dfnc[5,"y"]),abs(df$y[5]-dfc[5,"y"])),
"id_50" = c(df$y[50],dfnc[5,"y"],dfc[50,"y"],abs(df$y[50]-dfnc[50,"y"]),abs(df$y[50]-dfc[50,"y"])),
"id_100" = c(df$y[100],dfnc[5,"y"],dfc[100,"y"],abs(df$y[100]-dfnc[100,"y"]),abs(df$y[100]-dfc[100,"y"])))
comparativa
which(is.na(dfc$y))
dfc[is.na(dfc)]=predict(object = lmlogit,newdata = dfpred)#inputa en dff las predicciones de Y
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_5" = c(df$y[5],dfnc[5,"y"],dfc[5,"y"],abs(df$y[5]-dfnc[5,"y"]),abs(df$y[5]-dfc[5,"y"])),
"id_50" = c(df$y[50],dfnc[5,"y"],dfc[50,"y"],abs(df$y[50]-dfnc[50,"y"]),abs(df$y[50]-dfc[50,"y"])),
"id_100" = c(df$y[100],dfnc[5,"y"],dfc[100,"y"],abs(df$y[100]-dfnc[100,"y"]),abs(df$y[100]-dfc[100,"y"])))
comparativa
confusionMatrix(as.factor(test$predbin), as.factor(test$z))
ECMnc = mean((dfnc$y - dfnc$pred)**2)
ECMnc
ECMnc = mean((dfc$y - dfc$pred)**2)
ECMnc = mean((dfnc$y - dfnc$pred)**2)
ECMc = mean((dfc$y - dfc$pred)**2)
ECMc
dfc$y
dfc$pred
dfc$pred = predict(object = lmlogit,dfc)
ECMc = mean((dfc$y - dfc$pred)**2)
ECMc
dfc=df_incompleto
dfpred= dfc[is.na(dfc$y),]
dftoprove= dfc[!is.na(dfc$y),]
dftoprove$id <- 1:nrow(dftoprove) #creo columna id
train <- dftoprove %>% dplyr::sample_frac(0.70) #70% como conjunto entrenamiento
test  <- dplyr::anti_join(dftoprove, train, by = 'id') #30% como conjunto prueba
train=train[,(names(train)!="id")]
test=test[,(names(test)!="id")]
#crea modelo lm de Regresión Lineal (para valores continuos)
lmlogit=lm(y ~ x1 + x2 + z, data = train)
#es lo mismo que: logit=glm(z ~ x1 + x2 + y, family = gaussian, data=train)
summary(lmlogit) #muestra el R cuadrado del train
test$pred=predict(object = lmlogit,newdata = test) #crea variable en test con las predicciones del dato
res=sum((test$y-test$pred)**2)
stc=sum((test$y-mean(test$y))**2)
r_cuadrado=1-res/stc #genera R cuadrado del test
#NO LO ENSEÑÓ, pero habría que comparar los resultados de los R cuadrados para ver si lo que dio en el train fue estadísticamente significativo y, por lo tanto, el train predice lo del test
#Si es significativo, enconces:
which(is.na(dfc$y))
dfc[is.na(dfc)]=predict(object = lmlogit,newdata = dfpred)#imputa en dfc las predicciones de Y
dfc
dfc$pred = predict(object = lmlogit,dfc)
ECMc = mean((dfc$y - dfc$pred)**2)
ECMc
comparativa=data.frame(
"termino" = c("dato_real","dato_modelo_nc","dato_modelo_c","dif real y nc","dif real y c"),
"id_5" = c(df$y[5],dfnc[5,"y"],dfc[5,"y"],abs(df$y[5]-dfnc[5,"y"]),abs(df$y[5]-dfc[5,"y"])),
"id_50" = c(df$y[50],dfnc[5,"y"],dfc[50,"y"],abs(df$y[50]-dfnc[50,"y"]),abs(df$y[50]-dfc[50,"y"])),
"id_100" = c(df$y[100],dfnc[5,"y"],dfc[100,"y"],abs(df$y[100]-dfnc[100,"y"]),abs(df$y[100]-dfc[100,"y"])))
comparativa
#B) Incorporar al menos 2 visualizaciones (con ggplot o no)
ggplot(dt,aes(dt$loudness,dt$energy))+geom_point() + geom_smooth(method="lm")
dt = read_csv('spotify.csv')
credit_card_db=read.csv("creditcard.csv")
clusterdb=USArrests
summary(clusterdb) #tienen diferentes escalas entonces requiere escalar
escalable=clusterdb
escalable=scale(escalable)
#determinar k:
#Hace todos los métodos
NbClust(escalable,min.nc = 2,max.nc = 10,method = "complete",index = "all")
#library(cluster)
library(NbClust)
#determinar k:
#Hace todos los métodos
NbClust(escalable,min.nc = 2,max.nc = 10,method = "complete",index = "all")
#Hace método del codo (elbow)
fviz_nbclust(escalable, kmeans, method = "wss")+geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
library(cluster)
#Hace método del codo (elbow)
fviz_nbclust(escalable, kmeans, method = "wss")+geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
library(factoextra)
#Hace método del codo (elbow)
fviz_nbclust(escalable, kmeans, method = "wss")+geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
res_km=kmeans(escalable,4,nstart = 25)
fviz_cluster(res_km,db,frame.type="convex")
fviz_cluster(res_km,clusterdb,frame.type="convex")
clusterdb$cluster=res_km$cluster
agrupaciones = clusterdb %>% group_by(cluster) %>% summarise(murder=mean(Murder),asaltos=mean(Assault),poblacion_urbana=mean(UrbanPop),rape=mean(Rape))
agrupaciones#análisis por grupo
pcadb=clusterdb
View(USArrests)
pcadb=USArrests
pcadb_sin_cluster=pcadb %>% dplyr::select(-cluster) #xq no es una variable que explique
pcadb=iris
pcadb=iris
pcadb_sin_species=pcadb %>% dplyr::select(-Species) #xq no es una variable que explique
corrplot(cor(pcadb_sin_species),method = "ellipse")
library(corrplot)
corrplot(cor(pcadb_sin_species),method = "ellipse")
cp=prcomp(pcadb_sin_species,scale=T) #saca componentes principales
summary(cp)
#hace PCA
pca=PCA(X = pcadb_sin_cluster, scale.unit = TRUE, ncp = 2, graph = T)#el graph=T devuelve matriz de rotación y gráfico de componentes
#hace PCA
pca=PCA(X = pcadb_sin_species, scale.unit = TRUE, ncp = 2, graph = T)#el graph=T devuelve matriz de rotación y gráfico de componentes
#hace PCA
library(PCA)
#hace PCA
library(FactoMineR)
pca=PCA(X = pcadb_sin_species, scale.unit = TRUE, ncp = 2, graph = T)#el graph=T devuelve matriz de rotación y gráfico de componentes
#gráfico de componentes (por individuo/registro)
fviz_pca_ind(pca, geom.ind = "point",
col.ind = "#FC4E07",
axes = c(1, 2),
pointsize = 1.5)
#gráfico de componentes (por individuo/registro) pero coloreado por cada cluster
pcadb=cbind(pcadb,pca$ind$coord)
pcadb %>% ggplot(aes(Dim.1,Dim.2,colour=as.factor(Species))) + geom_point()
#matriz de rotación
rotation=cp$rotation
rotation
#matriz de rotación
cp$rotation
#Un uso de PCA podría ser calcular un índice de peligrosidad
#este índice explica el 60% de la varianza total del dataset
pcadb2=clusterdb
#Un uso de PCA podría ser calcular un índice de peligrosidad
#este índice explica el 60% de la varianza total del dataset
pcadb2=iris
summary(cp)
pca_1cp=PCA(X = pcadb2, scale.unit = TRUE, ncp = 1, graph = T)
#Un uso de PCA podría ser calcular un índice de peligrosidad
#este índice explica el 72% de la varianza total del dataset
pcadb2=pcadb_sin_species
pca_1cp=PCA(X = pcadb2, scale.unit = TRUE, ncp = 1, graph = T)
pca_1cp
pcadb2$indice=pca_1cp$ind$coord
pcadb2 %>% arrange(desc(indice))
mask=read.csv("MaskBeliefs.csv")
mask=read.csv("MaskBeliefs.csv")
mask_sup=mask %>% select(Gender)
#a) ¿Cuanto del segundo componente se explica por el Genero?
mca = MCA(mask,graph=T)
fviz_screeplot(mca)
mca$svd$vs #muestra autovalores de los componentes
round(mca$svd$vs**2/sum(mca$svd$vs**2),3) #muestra proporciones de explicación de la variablidad total de cada componente
#hace gráfico de variables
fviz_mca_var(mca, col.var = "cos2", #represents the quality of the representation for variables on the factor map
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, # Avoid text overlapping
ggtheme = theme_minimal())
cp1 = mca$svd$U %>% as_tibble() #tomo solo el primer componente
h1 = cbind(mask,cp1)
cp4 = mca$svd$U[,1:4] %>% as_tibble() #tomo los primeros 4 componentes
h4=cbind(mask,cp4)
lm(V2~Gender, h1) %>% summary()
lm(V2~Gender, h4) %>% summary()
cp1
cp1 = mca$svd$U[,1] %>% as_tibble() #tomo solo el primer componente
cp1
h1 = cbind(mask,cp1)
h1
cp2 = mca$svd$U[,2] %>% as_tibble() #tomo solo el primer componente
cp2
cp4 = mca$svd$U[,1:4] %>% as_tibble() #tomo los primeros 4 componentes
cp4
cp2 = mca$svd$U[,1:2] %>% as_tibble() #tomo solo el primer componente
h2 = cbind(mask,cp1)
cp2
h2 = cbind(mask,cp1)
h2 = cbind(mask,cp2)
lm(V2~Gender, h2) %>% summary()
lm(V2~Gender, h4) %>% summary()
#b) ¿Cuanto del primer componente se explica por creer que evita el contagio?
lm(V1~PreventSpread, h2) %>% summary()
lm(V1~PreventSpread, h4) %>% summary()
#hace gráfico de variables
fviz_mca_var(mca, col.var = "cos2", #represents the quality of the representation for variables on the factor map
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, # Avoid text overlapping
ggtheme = theme_minimal())
#c) Analizando el segundo componente, ¿cual es el vinculo entre el genero y el motivo del uso del barbijo? (que categorías estan cercas unas de otras)
#hace gráfico de variables
fviz_mca_var(mca, col.var = "cos2", #represents the quality of the representation for variables on the factor map
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, # Avoid text overlapping
ggtheme = theme_minimal())
#e) Estudiar los componentes extraidos a la luz de la variable Public
h2 %>% ggplot(aes(x=V1,y=V2,color=Public))+geom_point(alpha = 0.7)
#O si se quiere visualizar un solo componente principal con la variable
h2 %>% ggplot(aes(x=V1,y=0,color=Public))+geom_point(alpha = 0.7)
mask
brand.ratings <- read.csv("http://goo.gl/IQl8nc") %>% as_tibble()
brand.nm = brand.ratings[,1:9] #saca la marca
r.mat = cor(brand.nm) #saca matriz de correlación
corrplot(r.mat)
corrplot(r.mat)
#factores
eigens <- eigen(r.mat) #muestra autovalores
eigens$values/sum(eigens$values) #muestra porcentaje de variabilidad que explica cada uno
#Cantidad de Factores:
#1-Todos los test
nS = nScree(r.mat)
brand.ratings <- read.csv("http://goo.gl/IQl8nc") %>% as_tibble()
brand.nm = brand.ratings[,1:9] #saca la marca
brand.nm = brand.ratings[,1:9] #saca la marca
r.mat = cor(brand.nm) #saca matriz de correlación
corrplot(r.mat)
#factores
eigens <- eigen(r.mat) #muestra autovalores
eigens$values/sum(eigens$values) #muestra porcentaje de variabilidad que explica cada uno
#Cantidad de Factores:
#1-Todos los test
nS = nScree(r.mat)
library(nFactors)
#Cantidad de Factores:
#1-Todos los test
nS = nScree(r.mat)
#Cantidad de Factores:
#1-Todos los test
nS = nScree(r.mat)
plotnScree(nS) #Prueba con todos los test. En este caso todos sugieren 3 factores.
#2-Scree Test
eigendf = enframe(eigens$values)
eigendf$random = eigens$values #tomo los factores con autovalores mayores a 1
nfactors=2 #tomo 2 factores para poder graficar
fact2 = factanal(brand.nm, factors=nfactors, rotation = 'oblimin',scores="Bartlett")
semPaths(f2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
library(GPArotation)
#library(RColorBrewer)
#library(gplots)
#library(semPlot)
fact2 = factanal(brand.nm, factors=nfactors, rotation = 'oblimin',scores="Bartlett")
semPaths(f2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
library(RColorBrewer)
semPaths(f2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
#library(RColorBrewer)
library(gplots)
semPaths(f2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
#library(RColorBrewer)
#library(gplots)
library(semPlot)
semPaths(f2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
fact2 = factanal(brand.nm, factors=nfactors, rotation = 'oblimin',scores="Bartlett")
semPaths(fact2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
fact3 = factanal(brand.nm, factors=nfactors+1)
semPaths(f3, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
semPaths(fact3, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
fact2 = factanal(brand.nm, factors=nfactors, rotation = 'none',scores="Bartlett")
semPaths(fact2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
#guarda valores de los factores
brand.scores = fact2$scores %>% as_tibble() #%>% ggplot(aes(Factor1,Factor2))+geom_point()
fact2$scores %>% as_tibble() %>% ggplot(aes(Factor1,Factor2))+geom_point()
brand.scores["brand"] = brand.ratings[,"brand"] #vuelve a insertar la marca
brand.fa.mean <- aggregate(. ~ brand, data=brand.scores, mean) #agrupa por marca
names(brand.fa.mean)=c("brand","precio","calidad")
rownames(brand.fa.mean)=brand.fa.mean[, 1]
brand.fa.mean %>% ggplot(aes(precio,calidad,col=brand))+geom_point() #grafica cada marca con respecto a sus dos factores (en este caso se determinó que representaban precio y calidad)
brand.fa.mean <- brand.fa.mean[, -1]
heatmap.2(as.matrix(brand.fa.mean),
col=brewer.pal(9, "GnBu"), trace="none", key=FALSE, dend="none",
cexCol=1.2, main="\n\n\n\n\n\nMean factor score by brand")
fact2$scores
brand.scores
brand.fa.mean
brand.scores
brand.fa.mean %>% ggplot(aes(precio,calidad,col=brand))+geom_point() #grafica cada marca con respecto a sus dos factores (en este caso se determinó que representaban precio y calidad)
brand.fa.mean <- aggregate(. ~ brand, data=brand.scores, mean) #agrupa por marca
names(brand.fa.mean)=c("brand","precio","calidad")
rownames(brand.fa.mean)=brand.fa.mean[, 1]
brand.fa.mean %>% ggplot(aes(precio,calidad,col=brand))+geom_point() #grafica cada marca con respecto a sus dos factores (en este caso se determinó que representaban precio y calidad)
fact2 = factanal(brand.nm, factors=nfactors, rotation = 'oblimin',scores="Bartlett")
semPaths(fact2, what="est", residuals=FALSE,
cut=0.3, posCol=c("white", "darkgreen"), negCol=c("white", "red"),
edge.label.cex=0.75, nCharNodes=7)
dt = read_csv('spotify.csv')
dt = read_csv('spotify.csv')
#A) Medidas de tendencia central (media,mediana,moda), variacion o frecuencia.
mean(dt$duration_ms)
median(dt$duration_ms)
moda <- function(vector) {
valores_unicos <- unique(vector)
cant_repeticiones <- tabulate(match(vector, valores_unicos))
return(valores_unicos[cant_repeticiones == max(cant_repeticiones)])
}
moda(dt$genre)
sd(dt$duration_ms)
frec=function(vector){
unicos=unique(vector)
return(tabulate(match(vector,unicos)))
}
frec(dt$genre)
#B) Incorporar al menos 2 visualizaciones (con ggplot o no)
ggplot(dt,aes(dt$loudness,dt$energy))+geom_point() + geom_smooth(method="lm")
ggplot(dt)+geom_point(aes(dt$liveness,dt$duration_ms))
#C) Establecer una pregunta que vincule dos variables numericas, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: Determinar si un nivel mayor de ruido repercute en un mayor nivel de energía
ggplot(dt,aes(dt$loudness,dt$energy))+geom_point() + geom_smooth(method="lm")
#A partir del gráfico, parece haber relación entre el ruido y la energía
#El test apropiado es el test de correlación
cor.test(dt_c$loudness,dt_c$energy)
#A partir del gráfico, parece haber relación entre el ruido y la energía
#El test apropiado es el test de correlación
cor.test(dt$loudness,dt$energy)
#D) Establecer una pregunta que vincule dos variables categoricas, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: Evaluar si existe independencia entre las variables mode y esplicit
plot(table(dt$explicit,dt$mode))
dt %>%
dt %>%
filter(!is.na(explicit)) %>%
group_by(explicit,mode) %>%
count() %>%
ggplot(aes(x=explicit,y=n,fill=as.factor(mode))) +
geom_bar(stat="identity",position="fill" #no evalúa el dato, sino su proporción)
#Gráficamente parece que las variables son independientes entre sí
#El test adecuado es el de Chi Cuadrado para evaluar la independencia entre las dos varibles categóricas
chisq.test(dt$explicit,dt$mode)
dt %>%
dt %>%
filter(!is.na(explicit)) %>%
group_by(explicit,mode) %>%
count() %>%
ggplot(aes(x=explicit,y=n,fill=as.factor(mode))) +
geom_bar(stat="identity",position="fill") #no evalúa el dato, sino su proporción
#Gráficamente parece que las variables son independientes entre sí
#El test adecuado es el de Chi Cuadrado para evaluar la independencia entre las dos varibles categóricas
chisq.test(dt$explicit,dt$mode)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
density(dt$loudness)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
densityplot(dt$loudness)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
dt %>% filter(explicit) %>% densityplot(dt$loudness)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
dt %>% filter(explicit==TRUE) %>% densityplot(dt$loudness)
dt %>% filter(explicit==TRUE)
dt %>% filter(explicit)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
dt %>% filter(explicit) %>% densityplot(loudness)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
dt %>% filter(explicit) %>% densityplot(.$loudness)
#E) Establecer una pregunta que vincule una variable categoricas y una numerica, determinar el test adecuado, ejecutarlo e interpretarlo
#Pregunta: La diferencia en Loudness varía significativamente dependiendo si la canción es explicit o no?
dt %>% filter(explicit) %>% ggplot(aes(x=explicit,y=n,fill=as.factor(mode))) +
geom_bar(stat="identity",position="fill") #no evalúa el dato, sino su proporción
ggplot(dt, aes(x=loudness, color=explicit)) + geom_density()
dt %>% filter(!is.na(explicit)) %>% ggplot(aes(x=loudness, color=explicit)) + geom_density()
dt[dt$explicit]$loudness
dt[,dt$explicit]
dt[dt$explicit,]$loudness
dt[dt$explicit,]
dt %>% filter(explicit)
dt %>% filter(explicit) %>% select(loudness)
dt %>% filter(!explicit)
t.test(dt %>% filter(explicit) %>% select(loudness), dt %>% filter(!explicit) %>% select(loudness))
